{"cells":[{"cell_type":"markdown","metadata":{"id":"UoVlGowgM0h3"},"source":["# Lab 05 Logistic Classification (diabetes)\n","* Logistic Classfication을 diabetes data를 활용하여 모델을 만들어 보도록 하겠습니다\n","### 기본 Library 선언 및 Tensorflow 버전 확인"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v1VxPMwuM0h5","executionInfo":{"status":"ok","timestamp":1685292874665,"user_tz":-540,"elapsed":7301,"user":{"displayName":"유광현","userId":"16629314767644566100"}},"outputId":"53702e16-d527-4196-f7b9-419d749c1530"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.12.0\n"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers, Input\n","\n","tf.random.set_seed(0)   # for reproducibility\n","print(tf.__version__)"]},{"cell_type":"markdown","metadata":{"id":"TVZkJeNSM0h6"},"source":["### 강의에 설명할 Data입니다"]},{"cell_type":"code","execution_count":2,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"JV7pmmmsM0h7","executionInfo":{"status":"ok","timestamp":1685293574496,"user_tz":-540,"elapsed":280,"user":{"displayName":"유광현","userId":"16629314767644566100"}},"outputId":"e890c81e-2cbe-4337-fbc9-e5dbe2c61e5d"},"outputs":[{"output_type":"stream","name":"stdout","text":["(759, 8) (759, 1)\n","[[-0.294118   0.487437   0.180328  ... -0.53117   -0.0333333  0.       ]\n"," [-0.882353  -0.145729   0.0819672 ... -0.766866  -0.666667   1.       ]\n"," [-0.0588235  0.839196   0.0491803 ... -0.492741  -0.633333   0.       ]\n"," ...\n"," [-0.411765   0.21608    0.180328  ... -0.857387  -0.7        1.       ]\n"," [-0.882353   0.266332  -0.0163934 ... -0.768574  -0.133333   0.       ]\n"," [-0.882353  -0.0653266  0.147541  ... -0.797609  -0.933333   1.       ]]\n"]}],"source":["xy = np.loadtxt('data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n","x_train = xy[:, 0:-1]\n","y_train = xy[:, [-1]]\n","\n","print(x_train.shape, y_train.shape)\n","print(xy)"]},{"cell_type":"markdown","metadata":{"id":"IIOT1MvuM0h7"},"source":["##  Tensorflow\n","### 위 Data를 기준으로 가설의 검증을 통해 Logistic Classification 모델을 만들도록 하겠습니다\n","* Tensorflow data API를 통해 학습시킬 값들을 담는다 (Batch Size는 한번에 학습시킬 Size로 정한다)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"zu7Wv0aAM0h7","executionInfo":{"status":"ok","timestamp":1685293581141,"user_tz":-540,"elapsed":275,"user":{"displayName":"유광현","userId":"16629314767644566100"}}},"outputs":[],"source":["dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))"]},{"cell_type":"markdown","metadata":{"id":"vdf32ZVFM0h8"},"source":["### 위 Data를 기준으로 가설의 검증을 통해 Logistic Classification 모델을 만들도록 하겠습니다\n","* W와 b은 학습을 통해 생성되는 모델에 쓰이는 Wegith와 Bias (초기값을 variable : 0이나 Random값으로 가능 tf.random_normal([2, 1]) )"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"WBjtFb2eM0h8","executionInfo":{"status":"ok","timestamp":1685293593550,"user_tz":-540,"elapsed":2,"user":{"displayName":"유광현","userId":"16629314767644566100"}}},"outputs":[],"source":["W = tf.Variable(tf.random.normal([8, 1]), name='weight')\n","b = tf.Variable(tf.random.normal([1]), name='bias')"]},{"cell_type":"markdown","metadata":{"id":"TLiHgd5kM0h8"},"source":["### Sigmoid 함수를 가설로 선언합니다\n","* Sigmoid는 아래 그래프와 같이 0과 1의 값만을 리턴합니다 tf.sigmoid(tf.matmul(X, W) + b)와 같습니다\n","\n","$$\n","\\begin{align}\n","sigmoid(x) & = \\frac{1}{1+e^{-x}}  \\\\\\\\\\\n","\\end{align}\n","$$\n","\n","![sigmoid](https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"eXp9-97TM0h8","executionInfo":{"status":"ok","timestamp":1685293596970,"user_tz":-540,"elapsed":265,"user":{"displayName":"유광현","userId":"16629314767644566100"}}},"outputs":[],"source":["def logistic_regression(features):\n","    hypothesis  = tf.math.sigmoid(tf.matmul(features, W) + b)\n","    return hypothesis"]},{"cell_type":"markdown","metadata":{"id":"BDshVXs8M0h9"},"source":["### 가설을 검증할 Cost 함수를 정의합니다\n","$$\n","\\begin{align}\n","cost(h(x),y) & = −log(h(x))  &  if  &  y=1 \\\\\\\\\\\n","cost(h(x),y) & = -log(1−h(x))  &  if  &  y=0\n","\\end{align}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"MLJGUNBHM0h9"},"source":["* 위 두수식을 합치면 아래과 같습니다\n","$$\n","\\begin{align}\n","cost(h(x),y) & = −y log(h(x))−(1−y)log(1−h(x))\n","\\end{align}\n","$$"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"lnJEf7QCM0h9","executionInfo":{"status":"ok","timestamp":1685293977992,"user_tz":-540,"elapsed":304,"user":{"displayName":"유광현","userId":"16629314767644566100"}}},"outputs":[],"source":["def loss_fn(hypothesis, features, labels):\n","    cost = -tf.reduce_mean(labels * tf.math.log(logistic_regression(features)) + (1 - labels) * tf.math.log(1 - hypothesis))\n","    return cost\n","\n","optimizer = tf.keras.optimizers.experimental.SGD(learning_rate=0.01)"]},{"cell_type":"markdown","metadata":{"id":"bi92GsN2M0h-"},"source":["### 추론한 값은 0.5를 기준(Sigmoid 그래프 참조)로 0과 1의 값을 리턴합니다.\n","* Sigmoid 함수를 통해 예측값이 0.5보다 크면 1을 반환하고 0.5보다 작으면 0으로 반환합니다."]},{"cell_type":"code","execution_count":38,"metadata":{"id":"2eA4Uvj1M0h-","executionInfo":{"status":"ok","timestamp":1685295036705,"user_tz":-540,"elapsed":4,"user":{"displayName":"유광현","userId":"16629314767644566100"}}},"outputs":[],"source":["def accuracy_fn(hypothesis, labels):\n","    predicted = tf.cast(hypothesis > 0.5, dtype=tf.int32)\n","    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.float32))\n","    return accuracy"]},{"cell_type":"markdown","metadata":{"id":"eNTAYZxFM0h-"},"source":["### GradientTape를 통해 경사값을 계산합니다."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"VIKqz3dLM0h-","executionInfo":{"status":"ok","timestamp":1685293959984,"user_tz":-540,"elapsed":2,"user":{"displayName":"유광현","userId":"16629314767644566100"}}},"outputs":[],"source":["def grad(hypothesis, features, labels):\n","    with tf.GradientTape() as tape:\n","        loss_value = loss_fn(logistic_regression(features),features,labels)\n","    return tape.gradient(loss_value, [W,b])"]},{"cell_type":"markdown","metadata":{"id":"aPgt-Zl7M0h_"},"source":["### Tensorflow를 통해 실행합니다.\n","* 위의 Data를 Cost함수를 통해 학습시킨 후 모델을 생성합니다. "]},{"cell_type":"code","execution_count":20,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"a0BxIDUWM0h_","executionInfo":{"status":"ok","timestamp":1685294012700,"user_tz":-540,"elapsed":28743,"user":{"displayName":"유광현","userId":"16629314767644566100"}},"outputId":"a98a3e54-f8f1-470e-82eb-c96dcb66fd3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iter: 0, Loss: 0.6533\n","Iter: 100, Loss: 0.6448\n","Iter: 200, Loss: 0.6367\n","Iter: 300, Loss: 0.6291\n","Iter: 400, Loss: 0.6219\n","Iter: 500, Loss: 0.6151\n","Iter: 600, Loss: 0.6086\n","Iter: 700, Loss: 0.6025\n","Iter: 800, Loss: 0.5968\n","Iter: 900, Loss: 0.5913\n","Iter: 1000, Loss: 0.5862\n","Iter: 1100, Loss: 0.5813\n","Iter: 1200, Loss: 0.5767\n","Iter: 1300, Loss: 0.5723\n","Iter: 1400, Loss: 0.5682\n","Iter: 1500, Loss: 0.5643\n","Iter: 1600, Loss: 0.5606\n","Iter: 1700, Loss: 0.5571\n","Iter: 1800, Loss: 0.5537\n","Iter: 1900, Loss: 0.5506\n","Iter: 2000, Loss: 0.5476\n"]}],"source":["EPOCHS = 2001\n","\n","for step in range(EPOCHS):\n","    for features, labels in iter(dataset):\n","        grads = grad(logistic_regression(features), features, labels)\n","        optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b]))\n","        if step % 100 == 0:\n","            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(logistic_regression(features),features,labels)))"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oCVXW8YOM0h_","executionInfo":{"status":"ok","timestamp":1685295274297,"user_tz":-540,"elapsed":279,"user":{"displayName":"유광현","userId":"16629314767644566100"}},"outputId":"8cf37d08-7ab3-4ffd-fd53-f2628582b8b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Hypothesis:  0.76016605 \n","Predicted (Y) : 1.0 \n","Lable (Y) : [1.]\n","Testset Accuracy: 1.0000\n"]}],"source":["test_x, test_y = x_train[1:2], y_train[1]\n","\n","hypothesis  = logistic_regression(test_x).numpy()[0][0]\n","predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n","accuracy = accuracy_fn(logistic_regression(test_x),test_y)\n","print(\"Hypothesis: \", hypothesis, \"\\nPredicted (Y) :\", predicted.numpy(), \"\\nLable (Y) :\", test_y)\n","print(\"Testset Accuracy: {:.4f}\".format(accuracy))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}